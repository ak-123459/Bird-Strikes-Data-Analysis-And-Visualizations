
<div align="center">
<a href="https://ibb.co/bPHp8kW"><img src="https://i.ibb.co/Y3DvqxR/Screenshot-2024-11-08-174914.png" alt="Screenshot-2024-11-08-174914" border="0"></a>

  ## Bird-Strikes-Data Analysis And Visualizations
</div> 

<br></br>


Welcome to the data analysis project repository! This project focuses on analyzing Bird Strikes data in USA Airlines.objective to apply different data analyis techniques ex. visualization,EDA,statatics to find the birdstrikes trends and patterns over the years.
In above Bird Strikes Visualization.pdf file I have Specified all report and insights after the overall data analysis project.




This repository contains code to fine-tune the `bert-base-cased` model for Named Entity Recognition (NER) on university-related data, targeting entities such as department names, course titles, and academic roles.

## **Table of Contents**
1. [Project Overview](#project-overview)
2. [Dataset](#dataset)
3. [Requirements](#requirements)
4. [Setup](#setup)
5. [Training the Model](#training-the-model)
6. [Evaluating the Model](#evaluating-the-model)
7. [Inference](#inference)
8. [Results](#results)

## **Project Overview**

We know that in this technical and more advance world transportations play key role in the world.In the aeroplane services sometimes some delay can lead thousands od dollar loss and also other accidental events.so in this case I have analyse the data of USA country  to understand the key factor and areas where most strikes occurs and find the patttern to for more better understanding.we  use for  the visualization tools like plotly for more intractive visual understanding of data.All visuals and report is presented on the **Bird Strikes Data Visualization.pdf** file in the above section.and all python code of that visualization on the notebook file **BirdStrikeDataAnalysis.ipynb**.

###  <a href="https://imgbb.com/"><img src="https://i.ibb.co/D9vKsxH/dataset.png" alt="dataset" border="0"  width="50"></a> 
 
ðŸ”— Download Dataset- [Bird Strikes data]([https://link-to-your-dataset.com](https://docs.google.com/spreadsheets/d/1PF1PQ4-qg4ySrtyOXiF6SFGX7P0Qfl_r/edit?usp=sharing&ouid=108302795397133931709&rtpof=true&sd=true)) 





3. [Requirements](#requirements)


<div id="badges" align="start">

  <a >
    <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="tensorflow"/>
  </a>


   <a >
    <img src="https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252" alt="colab"/>

     
  </a>

   <a >
    <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="tensorflow"/>

  </a>
 
</div>


<a >
<img src="https://i.ibb.co/k2F2Bgz/llms-800x800.png" alt="llms-800x800" border="0"  width="100"/>
  </a>



  4. [Acknowledgments](#acknowledgments)

During overall training how to load dataset ,prepare dataset,tokenized dataset and how to train the model and after how to evaluate the model.we test and validate model on both test and validations dataset we can run multiple epochs to decreased the validation loss.


# Note:- 
**For More details about how to fine tune bert-base-case please check the google colab notebook above.**





